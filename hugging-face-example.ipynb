{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Especializar um Modelo Pr√©-treinado do Hugging Face\n",
    "\n",
    "Este notebook apresenta um roteiro que detalha os passos necess√°rios para utilizar e especializar modelos de linguagem pr√©-treinados para a tarefa de sumariza√ß√£o de textos em portugu√™s, garantindo a instala√ß√£o e configura√ß√£o adequadas das bibliotecas necess√°rias, bem como a sele√ß√£o e utiliza√ß√£o de modelos apropriados para o idioma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Instala√ß√£o de depend√™ncias\n",
    "Execute o seguinte bloco para instalar e atualizar as depend√™ncias. Em seguida reinicie o kernel antes de executar os demais blocos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers datasets torch\n",
    "!pip install sentencepiece\n",
    "!pip install tf-keras\n",
    "!pip install transformers[torch] -U\n",
    "!pip install accelerate -U\n",
    "!pip install transformers datasets torch accelerate -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Carregamento do Corpus e Pr√©-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# Carrega o corpus do arquivo gerado pelo outro notebook deste reposit√≥rio.\n",
    "dataset = load_dataset('csv', data_files='combined_corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'texto', 'summary'],\n",
      "        num_rows: 82\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'texto', 'summary'],\n",
      "        num_rows: 10\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# Dividi o dataset em 90% para treino e 10% para valida√ß√£o\n",
    "train_test_split = dataset['train'].train_test_split(test_size=0.1)\n",
    "dataset = DatasetDict({\n",
    "    'train': train_test_split['train'],\n",
    "    'validation': train_test_split['test']\n",
    "})\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Escolha do Modelo Pr√©-Treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"rhaymison/flan-t5-portuguese-small-summarization\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tokeniza√ß√£o e Prepara√ß√£o dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a672c17adb647389a0a635047ce1ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/82 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jcf_s\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128c91189ea34980b35ed818856ced88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [doc for doc in examples['texto']]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples['summary'], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Configura√ß√£o do Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jcf_s\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0676c6eee634428c9a41936df28102fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10fd12089f644a8e91ad67fb0843f2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0828173160552979, 'eval_runtime': 6.1723, 'eval_samples_per_second': 1.62, 'eval_steps_per_second': 0.324, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a773fbb29a4bd0ab52e7be871a6fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0470554828643799, 'eval_runtime': 6.1401, 'eval_samples_per_second': 1.629, 'eval_steps_per_second': 0.326, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6fceb89e41d4c78ba19d5db9848c479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.032470941543579, 'eval_runtime': 6.3361, 'eval_samples_per_second': 1.578, 'eval_steps_per_second': 0.316, 'epoch': 3.0}\n",
      "{'train_runtime': 738.1138, 'train_samples_per_second': 0.333, 'train_steps_per_second': 0.045, 'train_loss': 1.342020323782256, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=33, training_loss=1.342020323782256, metrics={'train_runtime': 738.1138, 'train_samples_per_second': 0.333, 'train_steps_per_second': 0.045, 'total_flos': 45729064157184.0, 'train_loss': 1.342020323782256, 'epoch': 3.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Avalia√ß√£o e Ajustes Finais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a030d6886d19444f84d559917275a70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.032470941543579, 'eval_runtime': 6.294, 'eval_samples_per_second': 1.589, 'eval_steps_per_second': 0.318, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "results = trainer.evaluate()\n",
    "\n",
    "pprint(results, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Registrando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./final_model\\\\tokenizer_config.json',\n",
       " './final_model\\\\special_tokens_map.json',\n",
       " './final_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./final_model')\n",
    "tokenizer.save_pretrained('./final_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Uso do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5653 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumo do texto:\n",
      "Setor de Defesa √© aprovado pela Resolu√ßo ConSUG/MD no 6, de 11 de dezembro de 2020, e especialistas apontam que o Plano Estrat√©gico Setorial 2024-2027 est√° alinhado com a cadeia de valor setorial, adequadamente preparadas e fortalecimento dos objetivos nacionais, como a primeira esfor√ßo da cidadania. Resultado de estudos e debates sobre temas ligados ao enfrentamento nacional e defeso no significa exclusividade para o desenvolvimento\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Carregar o modelo treinado\n",
    "summarizer = pipeline('summarization', model='./final_model', tokenizer='./final_model')\n",
    "\n",
    "# Caminho para o arquivo de teste\n",
    "test_file_path = 'input-test.txt'\n",
    "\n",
    "# Ler todo o conte√∫do do arquivo de teste\n",
    "with open(test_file_path, 'r', encoding='utf-8') as file:\n",
    "    test_text = file.read().strip()\n",
    "\n",
    "# Sumarizar o texto do arquivo\n",
    "summary = summarizer(test_text)[0]['summary_text']\n",
    "\n",
    "# Exibir o resumo\n",
    "print(\"Resumo do texto:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setor de Defesa √© aprovado pela Resolu√ßo ConSUG/MD no 6, de 11 de dezembro de 2020, e especialistas apontam que o Plano Estrat√©gico Setorial 2024-2027 est√° alinhado com a cadeia de valor setorial, adequadamente preparadas e fortalecimento dos objetivos nacionais, como a primeira esfor√ßo da cidadania. Resultado de estudos e debates sobre temas ligados ao enfrentamento nacional e defeso no significa exclusividade para o desenvolvimento"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
