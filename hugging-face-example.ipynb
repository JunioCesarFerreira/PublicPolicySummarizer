{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Especializar um Modelo Pré-treinado do Hugging Face\n",
    "\n",
    "Este notebook apresenta um roteiro que detalha os passos necessários para utilizar e especializar modelos de linguagem pré-treinados para a tarefa de sumarização de textos em português, garantindo a instalação e configuração adequadas das bibliotecas necessárias, bem como a seleção e utilização de modelos apropriados para o idioma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Instalação de dependências\n",
    "Execute o seguinte bloco para instalar e atualizar as dependências. Em seguida reinicie o kernel antes de executar os demais blocos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers datasets torch\n",
    "!pip install sentencepiece\n",
    "!pip install tf-keras\n",
    "!pip install transformers[torch] -U\n",
    "!pip install accelerate -U\n",
    "!pip install transformers datasets torch accelerate -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Carregamento do Corpus e Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Carrega o corpus do arquivo gerado pelo outro notebook deste repositório.\n",
    "dataset = load_dataset('csv', data_files='combined_corpus.csv')\n",
    "\n",
    "dataset = dataset.map(lambda x: {'texto': clean_text(x['texto'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'texto', 'summary'],\n",
      "        num_rows: 82\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'texto', 'summary'],\n",
      "        num_rows: 10\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# Divide o dataset em 90% para treino e 10% para validação\n",
    "train_test_split = dataset['train'].train_test_split(test_size=0.1)\n",
    "dataset = DatasetDict({\n",
    "    'train': train_test_split['train'],\n",
    "    'validation': train_test_split['test']\n",
    "})\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Escolha do Modelo Pré-Treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"rhaymison/flan-t5-portuguese-small-summarization\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tokenização e Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300e8f8556864dc88c9108419fa1f086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/82 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3a7602efe24020ba42e70f91b0f461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    max_length = 512\n",
    "    inputs = tokenizer(examples['texto'], padding='max_length', truncation=True, max_length=max_length)\n",
    "    labels = tokenizer(examples['summary'], padding='max_length', truncation=True, max_length=max_length)\n",
    "    \n",
    "    inputs['labels'] = labels['input_ids']\n",
    "    return inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Configuração do Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy='epoch',\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=5,\n",
    "    predict_with_generate=True\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02d42982e7e4bc2b76adabe20d35682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81238e3598054e2b9d53cf3a78039b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.677910804748535, 'eval_runtime': 13.3081, 'eval_samples_per_second': 0.751, 'eval_steps_per_second': 0.15, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c3e575e7674768bef26c2b1d26387f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2672119140625, 'eval_runtime': 13.7844, 'eval_samples_per_second': 0.725, 'eval_steps_per_second': 0.145, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe018dd914947fab95d397611fa3c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.9717087745666504, 'eval_runtime': 13.7299, 'eval_samples_per_second': 0.728, 'eval_steps_per_second': 0.146, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0004c0045341679b15a9883d1b2644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.810332775115967, 'eval_runtime': 13.5307, 'eval_samples_per_second': 0.739, 'eval_steps_per_second': 0.148, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db85fed92db54b0597b5fbef2db74575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7497737407684326, 'eval_runtime': 13.6637, 'eval_samples_per_second': 0.732, 'eval_steps_per_second': 0.146, 'epoch': 5.0}\n",
      "{'train_runtime': 3307.8163, 'train_samples_per_second': 0.124, 'train_steps_per_second': 0.017, 'train_loss': 5.695299738103693, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=55, training_loss=5.695299738103693, metrics={'train_runtime': 3307.8163, 'train_samples_per_second': 0.124, 'train_steps_per_second': 0.017, 'total_flos': 76215106928640.0, 'train_loss': 5.695299738103693, 'epoch': 5.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Avaliação e Ajustes Finais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74fe66f6b491431a822614e7875255a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'epoch': 5.0,\n",
      "  'eval_loss': 2.7497737407684326,\n",
      "  'eval_runtime': 14.051,\n",
      "  'eval_samples_per_second': 0.712,\n",
      "  'eval_steps_per_second': 0.142}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "results = trainer.evaluate()\n",
    "\n",
    "pprint(results, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Registrando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./final_model\\\\tokenizer_config.json',\n",
       " './final_model\\\\special_tokens_map.json',\n",
       " './final_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./final_model')\n",
    "tokenizer.save_pretrained('./final_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Uso do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jcf_s\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5658 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumo do texto:\n",
      "Setor de Defesa é aprovado pela Resoluço ConSUG/MD no 2, de 2019, apresenta prioridades de recursos para o desenvolvimento nacional, integraçes nacionais e integridade internacionárias. Plano estratégico setorial é alinhado com a cadeia de valor setorial, adequadamente preparadas e permanentemente prontas fortalecimento da cidadania.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Carrega o modelo treinado\n",
    "summarizer = pipeline('summarization', model='./final_model', tokenizer='./final_model')\n",
    "\n",
    "# Caminho para o arquivo de teste\n",
    "test_file_path = 'input-test.txt'\n",
    "\n",
    "# Lê todo o conteúdo do arquivo de teste\n",
    "with open(test_file_path, 'r', encoding='utf-8') as file:\n",
    "    test_text = file.read().strip()\n",
    "\n",
    "# Define o limite máximo de tokens na saída\n",
    "max_length_output = 1024 \n",
    "min_length_output = 100\n",
    "\n",
    "# Resume o texto do arquivo\n",
    "summary = summarizer(\"sumarize:\" + test_text, max_length=max_length_output, min_length=min_length_output, do_sample=False)[0]['summary_text']\n",
    "\n",
    "# Exibir o resumo\n",
    "print(\"Resumo do texto:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teste 1\n",
    "Parâmetros:\n",
    "```py\n",
    "model_name = \"rhaymison/flan-t5-portuguese-small-summarization\"\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True\n",
    ")\n",
    "```\n",
    "Resultado:\n",
    "\n",
    "Setor de Defesa é aprovado pela Resoluço ConSUG/MD no 6, de 11 de dezembro de 2020, e especialistas apontam que o Plano Estratégico Setorial 2024-2027 está alinhado com a cadeia de valor setorial, adequadamente preparadas e fortalecimento dos objetivos nacionais, como a primeira esforço da cidadania. Resultado de estudos e debates sobre temas ligados ao enfrentamento nacional e defeso no significa exclusividade para o desenvolvimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teste 2\n",
    "Parâmetros:\n",
    "```py\n",
    "model_name = \"rhaymison/flan-t5-portuguese-small-summarization\"\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='steps',\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=5,\n",
    "    predict_with_generate=True\n",
    ")\n",
    "```\n",
    "\n",
    "Resultado:\n",
    "\n",
    "Conheça o Plano Estratégico Setorial 2024-2027 com o PESD 2020-2027, aprovado pela Resoluço ConSUG/MD no 6, de 11 de dezembro de 2019, apresenta a identidade estratégica do Setor de Defesa, como se segue em vigor, e esforço nacional, na garantia da lei e da ordem; entenda os objetivos para o desenvolvimento de recursos. Governo tem ainda especialistas que aconteceram o plano após a primeira açes de efetividade ao sistema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teste 3\n",
    "\n",
    "Parâmetros:\n",
    "```py\n",
    "model_name = \"rhaymison/flan-t5-portuguese-small-summarization\"\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=5,\n",
    "    predict_with_generate=True\n",
    ")\n",
    "```\n",
    "\n",
    "Resultado:\n",
    "\n",
    "O Plano Estratégico Setorial 2024-2027 é aprovado pela Resoluço ConSUG/MD no 6, de 11 de dezembro de 2019, e o Plano estabelece a prioridade do Setor de Defesa para o desenvolvimento nacional, com os objetivos de serem empregados para a integraçes nacionais, o controle, a proteça, em apoio à poltica externa, para promover a confiança mtua, coeso ambiental e controles martimas. Os efeitos ainda no acontece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste t5-portuguese-small-summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5657 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumo do texto:\n",
      "Setor de Defesa é aprovado pela Resoluço ConSUG/MD no 2, de 2019, após açes em vigor com os objetivos de recursos. Plano estratégico deve ser realizado pelo PES 2024-2027, e especialistas no so preparados para o desenvolvimento nacional, ainda como a esforço da cidadania.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Carrega o tokenizer e o modelo que foram treinados juntos\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"rhaymison/flan-t5-portuguese-small-summarization\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"rhaymison/flan-t5-portuguese-small-summarization\")\n",
    "\n",
    "# Configura o pipeline de sumarização\n",
    "summarization = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Texto de entrada\n",
    "test_file_path = 'input-test.txt'\n",
    "with open(test_file_path, 'r', encoding='utf-8') as file:\n",
    "    test_text = file.read().strip()\n",
    "\n",
    "# Realiza a sumarização\n",
    "output = summarization(\"sumarize: \" + test_text)\n",
    "\n",
    "# Exibe o resumo\n",
    "print(\"Resumo do texto:\")\n",
    "print(output[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setor de Defesa é aprovado pela Resoluço ConSUG/MD no 2, de 2019, após açes em vigor com os objetivos de recursos. Plano estratégico deve ser realizado pelo PES 2024-2027, e especialistas no so preparados para o desenvolvimento nacional, ainda como a esforço da cidadania."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
